# 7.4 Analysis of quicksort
## 7.4-1
We guess that $T(n) \geq cn^2$ for some constant c. Substituting this guess into recurrence, we obtain:

$$
\begin{eqnarray}
T(n) &=& \max_{0 \leq q \leq n - 1}(T(q) + T(n - q - 1)) + \Theta(n) \\\
&\geq& \max_{0 \leq q \leq n - 1}(cq^2 + c(n - q - 1)^2) + \Theta(n) \\\
&=& c\max_{0 \leq q \leq n - 1}(q^2 + (n - q - 1)^2) + \Theta(n) \\\
&=& c\max_{0 \leq q \leq n - 1}(2q^2 - 2(n - 1)q + (n - 1)^2) + \Theta(n)
\end{eqnarray}
$$

$f(q) = 2q^2 - 2(n - 1)q + (n - 1)^2$ is monotonically decreasing at $[0, \frac{n - 1}{2}]$, and monotonically increasing at $[\frac{n - 1}{2}, n - 1]$. So $\max_{0 \leq q \leq n - 1}(2q^2 - 2(n - 1)q + (n - 1)^2) = f(0) = f(n) = (n - 1)^2$. Thus:

$$
\begin{eqnarray}
T(n) &\geq& c(n - 1)^2 + \Theta(n) \\\
&=& c(n - 1)^2 + dn \\\
&=& cn^2 + (d - 2c)n + c \\\
&>& cn^2
\end{eqnarray}
$$

where the last step holds as long as $ d \geq 2c$.

So $T(n) = \Omega(n^2)$

## 7.4-2
The recurrence for the best-case is $T(n) = 2T(\frac{n}{2}) + \Theta(n)$. Let's solve it with the master method. We have $a = 2, b = 2, f(n) = \Theta(n)$, and thus we have that $n^{\log_b{a}} = n^{\log_2{2}} = n = \Theta(n)$. Since $f(n) = \Theta(n)$, we can apply case 2 of the master theorem and conclude that the solution is $T(n) = \Theta(n\lg{n})$. Thus, $T(n) = \Omega(n\lg{n})$.

## 7.4-3
We've already knew it in the first exercise.

## 7.4-4
We have:

$$
\begin{eqnarray}
E[X] &=& \sum_{i = 1}^{n - 1}\sum_{j = i + 1}^n \frac{2}{j - i + 1} \\\
&=& \sum_{i = 1}^{n - 1}\sum_{k = 1}^{n - i} \frac{2}{k + 1} \\\
&\geq& \sum_{i = 1}^{n - 1}\sum_{k = 1}^{n - i} \frac{2}{2k} \\\
&=& \sum_{i = 1}^{n - 1}\sum_{k = 1}^{n - i} \frac{1}{k} \\\
&=& \sum_{i = 1}^{n - 1}\sum_{k = 1}^{i} \frac{1}{k} \\\
&=& \sum_{i = 1}^{n - 1}(\ln{i} + O(1)) & \text{(A.7)} \\\
&=& \ln{((n - 1)!)} + (n - 1)O(1) \\\
&=& \Omega(n\lg{n}) + O(n) & \text{(Exercise 3.2-3)} \\\
&=& \Omega(n\lg{n})
\end{eqnarray}
$$

## 7.4-5
